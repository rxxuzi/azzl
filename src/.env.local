# .env.local
# 使用するときは.envに名前を変更してから使用してください。
# Ollamaのエンドポイント
OLLAMA_ENDPOINT="http://localhost:12345"

# データベースファイルのパス
DATABASE="../db/database.json"

# ベクトルデータベースファイルのパス
VECTOR_DB="../db/vec.db"

# ベクトル埋め込み時に使用するモデル
EMBEDDING_MODEL="mxbai-embed-large"

# クロスエンコーダーモデル
CROSS_ENCODER_MODEL="cross-encoder/ms-marco-MiniLM-L-6-v2"

# ベースとなるLLM（大規模言語モデル）
# azzl:durian か azzl:guavaモデルを使用してください
LLM_MODEL="azzl:durian"
# サーバーのポート
SERVE_PORT="16710"

# 静的ファイルのルートディレクトリ
SERVE_ROOT="../www"

# レスポンス結果の出力先
OUT_DIR="../out"

