import sys
import os
import argparse
import json
import time
import dotenv
import threading
from queue import Queue
from rich.progress import track
from rich.prompt import Confirm
from rich.console import Console
from gen.vector import generate_embedding, setup_chroma_collection
from gen.database import save_vector_db

# .envã‚’èª­ã¿è¾¼ã‚€
dotenv.load_dotenv()

# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ã‚¹
DEFAULT_DATABASE = os.getenv("DATABASE", "../db/database.json")
DEFAULT_VECTOR_DB = os.getenv("VECTOR_DB", "../db/vec.db")
DEFAULT_THREADS = 4  # ä¸¦åˆ—å‡¦ç†ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¹ãƒ¬ãƒƒãƒ‰æ•°

console = Console()


def load_documents_from_file(input_path: str) -> list:
    """ æŒ‡å®šã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€ """
    if not os.path.exists(input_path):
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ« '{input_path}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        sys.exit(1)

    with open(input_path, "r", encoding="utf-8") as f:
        return json.load(f)


def worker(queue: Queue, results: list):
    """ ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¹ãƒ¬ãƒƒãƒ‰ï¼šã‚­ãƒ¥ãƒ¼ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–ã‚Šå‡ºã—ã€åŸ‹ã‚è¾¼ã¿ã‚’ç”Ÿæˆ """
    while not queue.empty():
        i, doc = queue.get()
        embedding = generate_embedding(doc)
        results[i] = {"id": str(i), "embedding": embedding, "document": doc}
        queue.task_done()


def create_vector_db(input_file: str, output_file: str, threads: int, force: bool = False, verbose: bool = False):
    """
    ãƒ™ã‚¯ãƒˆãƒ«DBã‚’ä¸¦åˆ—å‡¦ç†ã§ä½œæˆã—ã€å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã™ã‚‹ã€‚
    """
    start_time = time.time()

    # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯
    if not force and os.path.exists(output_file):
        print(f"âš ï¸  è­¦å‘Š: å‡ºåŠ›å…ˆ '{output_file}' ã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™ã€‚")
        if not Confirm.ask("ä¸Šæ›¸ãã—ã¾ã™ã‹ï¼Ÿ"):
            print("ğŸ›‘ å‡¦ç†ã‚’ä¸­æ–­ã—ã¾ã—ãŸã€‚")
            sys.exit(1)

    print("ğŸ”§ ChromaDB ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ä¸­...")
    collection = setup_chroma_collection()

    print(f"ğŸ“‚ ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­: {input_file}")
    documents = load_documents_from_file(input_file)

    # ã‚­ãƒ¥ãƒ¼ã¨çµæœãƒªã‚¹ãƒˆã®ä½œæˆ
    queue = Queue()
    results = [None] * len(documents)

    for i, doc in enumerate(documents):
        queue.put((i, doc))

    print(f"âš¡ ä¸¦åˆ—å‡¦ç† ({threads}ã‚¹ãƒ¬ãƒƒãƒ‰) ã§åŸ‹ã‚è¾¼ã¿ã‚’ç”Ÿæˆä¸­...")

    # ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’ä½œæˆ
    workers = []
    for _ in range(threads):
        thread = threading.Thread(target=worker, args=(queue, results))
        thread.start()
        workers.append(thread)

    # é€²æ—ãƒãƒ¼ã‚’è¡¨ç¤º
    for _ in track(range(len(documents)), description="ğŸ“ ãƒ™ã‚¯ãƒˆãƒ«DBã‚’ä½œæˆä¸­..."):
        queue.join()

    # å…¨ã‚¹ãƒ¬ãƒƒãƒ‰ã®çµ‚äº†ã‚’å¾…ã¤
    for thread in workers:
        thread.join()

    # ChromaDB ã«ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
    for item in results:
        collection.add(
            ids=[item["id"]],
            embeddings=[item["embedding"]],
            documents=[item["document"]]
        )

    save_vector_db_to_file(results, output_file)

    end_time = time.time()
    elapsed_time = end_time - start_time

    print(f"âœ… ãƒ™ã‚¯ãƒˆãƒ«DBä½œæˆå®Œäº†: {output_file}")

    # è©³ç´°å‡ºåŠ›ï¼ˆ-v ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    if verbose:
        db_size = os.path.getsize(output_file) / (1024 * 1024)  # MBå˜ä½
        print(f"ğŸ•’ å‡¦ç†æ™‚é–“: {elapsed_time:.2f} ç§’")
        print(f"ğŸ“¦ DB ã‚µã‚¤ã‚º: {db_size:.2f} MB")
        print(f"ğŸ“„ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°: {len(documents)}")


def save_vector_db_to_file(vector_db: list, output_path: str):
    """ ãƒ™ã‚¯ãƒˆãƒ«DBã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã™ã‚‹ """
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(vector_db, f, ensure_ascii=False, indent=4)


def main():
    parser = argparse.ArgumentParser(
        description="ãƒ™ã‚¯ãƒˆãƒ«DBä½œæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ (RAGç”¨)",
        formatter_class=argparse.RawTextHelpFormatter
    )
    parser.add_argument(
        "input_file",
        nargs="?", 
        help="å…¥åŠ›ã¨ãªã‚‹ JSON ãƒ•ã‚¡ã‚¤ãƒ« (çœç•¥æ™‚ã¯ .env ã® DATABASE ã‚’ä½¿ç”¨)"
    )
    parser.add_argument(
        "-o", "--output",
        help="å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ« (çœç•¥æ™‚ã¯ .env ã® VECTOR_DB ã‚’ä½¿ç”¨)"
    )
    parser.add_argument(
        "-t", "--threads",
        type=int,
        default=DEFAULT_THREADS,
        help=f"ä¸¦åˆ—å‡¦ç†ã®ã‚¹ãƒ¬ãƒƒãƒ‰æ•° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {DEFAULT_THREADS})"
    )
    parser.add_argument(
        "-f", "--force",
        action="store_true",
        help="å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ—¢ã«å­˜åœ¨ã™ã‚‹å ´åˆã€ä¸Šæ›¸ãã™ã‚‹"
    )
    parser.add_argument(
        "-v", "--verbose",
        action="store_true",
        help="è©³ç´°æƒ…å ±ã‚’è¡¨ç¤º (å‡¦ç†æ™‚é–“ã€DBã‚µã‚¤ã‚ºãªã©)"
    )

    args = parser.parse_args()

    input_path = args.input_file if args.input_file else DEFAULT_DATABASE
    output_path = args.output if args.output else DEFAULT_VECTOR_DB

    print(f"ğŸ“Œ å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {input_path}")
    print(f"ğŸ“Œ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {output_path}")
    print(f"ğŸ”„ ã‚¹ãƒ¬ãƒƒãƒ‰æ•°: {args.threads}")

    create_vector_db(input_path, output_path, args.threads, force=args.force, verbose=args.verbose)


if __name__ == "__main__":
    main()
